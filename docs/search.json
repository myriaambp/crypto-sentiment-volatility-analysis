[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Behavioral Signals in Crypto: Analyzing Sentiment and Search Trends as Predictors of Market Volatility",
    "section": "",
    "text": "1 Introduction\nThis project examines how behavioral factors such as sentiment and attention shape cryptocurrency market dynamics between October 2024 and October 2025, focusing on Bitcoin and Ethereum. Motivated by my background in neuroscience and my interest in transitioning to finance, I am particularly drawn to understanding how patterns of human behavior manifest in financial data. Cryptocurrencies provide an ideal setting for this research because their prices are highly sensitive to collective mood and information flow, often reacting to changes in public sentiment and online search activity quite rapidly. The analysis centers on three questions: How daily sentiment fluctuations, whether optimistic or pessimistic, correlate with market volatility and returns, whether spikes in public attention, measured through Google search interest, precede or follow periods of heightened instability, and whether Bitcoin and Ethereum differ in how strongly they respond to these behavioral signals. Through these questions, the project aims to understand how behavioral and psychological dynamics influence financial market movements.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThis project integrates three open data sources to examine how market activity, online sentiment, and public attention evolve for Bitcoin and Ethereum between December 2, 2024 and December 1, 2025. This one year window corresponds to the maximum period available under the free tiers of the APIs used in this project: both CoinGecko and Santiment restrict historical access to approximately the past 365 days unless a paid plan is used.\nDaily market data come from the CoinGecko Market Data API, which compiles cryptocurrency prices, trading volumes, and market capitalization across major global exchanges. Online sentiment is obtained from the Santiment API, which analyzes social media discussions and other text based signals to estimate the overall tone toward each asset. Public attention is measured using Google Trends, accessed through the gtrendsR package in R, which provides normalized daily search interest for the keywords “bitcoin” and “ethereum.”\nAPI requests require authentication, so all keys were stored privately in my .Renviron file. The data pull script automatically downloads the raw JSON responses, converts them into CSV files, and stores them in data/raw/. These raw files are then cleaned, standardized, and merged by coin and date. This includes aligning timestamps to a daily frequency, normalizing sentiment values, and handling a small number of missing days, primarily dates where Santiment did not report sentiment data, which is common due to API rate limits or gaps in social media coverage.\nThe final merged dataset contains one full year of daily observations for each coin and provides a reproducible foundation for exploring how market conditions, sentiment, and search behavior relate to cryptocurrency volatility.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Data Sources\nCoinGecko Market Data API:\nhttps://www.coingecko.com/en/api\nSantiment API:\nhttps://api.santiment.net\nGoogle Trends via gtrendsR:\n(Daily search interest for “bitcoin” and “ethereum”)\nAll data collection and preprocessing steps are contained in 1 Data Pull.qmd, which downloads data from all three APIs, saves raw files to data/raw/, and writes the cleaned, merged dataset to data/clean/merged_crypto_sentiment_trends.csv.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\nThe goal of this section is to describe where these gaps occur, whether they follow meaningful patterns, and how they should be handled prior to analysis.\n\n2.2.1 Missingness Summary\n\n\nCode\n#| message: false\n#| warning: false\n\n# Load all libraries silently\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(naniar)\n  library(janitor)\n  library(here)\n  library(scales)\n  library(zoo)\n})\n\ndf &lt;- read_csv(here(\"data\", \"clean\", \"merged_crypto_sentiment_trends.csv\"), show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n\n\n\nCode\ndf |&gt;\n  summarise(across(everything(), ~ sum(is.na(.)))) |&gt;\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"missing_count\") |&gt;\n  arrange(desc(missing_count))\n\n\nTo compare missingness across variables, the plot below shows the percentage of missing values for each variable within each coin.\n\n\nCode\nnice_names &lt;- c(\n  daily_return    = \"Daily Return\",\n  date            = \"Date\",\n  market_cap      = \"Market Cap\",\n  price           = \"Price\",\n  search_interest = \"Search Interest\",\n  sentiment_score = \"Sentiment Score\",\n  volatility_7d   = \"7-Day Volatility\",\n  volume          = \"Volume\",\n  coin            = \"Coin\"\n)\n\nmiss_coin &lt;- df |&gt;\n  mutate(across(everything(), ~ is.na(.), .names = \"miss_{col}\")) |&gt;\n  group_by(coin) |&gt;\n  summarise(across(starts_with(\"miss_\"), mean)) |&gt;\n  pivot_longer(\n    cols = starts_with(\"miss_\"),\n    names_to = \"variable\",\n    values_to = \"missing_prop\"\n  ) |&gt;\n  mutate(\n    missing_pct = missing_prop * 100,\n    variable = str_remove(variable, \"miss_\"),\n    variable = nice_names[variable]\n  )\n\nggplot(miss_coin, aes(x = fct_reorder(variable, missing_pct), y = missing_pct)) +\n  geom_col(fill = \"#3182bd\") +\n  facet_grid(\n    rows = vars(coin),\n    scales = \"free_x\",\n    switch = \"x\"\n  ) +\n  labs(\n    x = NULL,\n    y = \"Percent Missing\",\n    title = \"Missingness by Coin\"\n  ) +\n  scale_y_continuous(labels = label_percent(scale = 1)) +\n  theme_grey(base_size = 16) +\n  theme(\n    strip.placement = \"outside\",\n    strip.text = element_text(size = 14, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),\n    axis.text.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nThe plot shows that missingness is concentrated in variables that rely on external data sources rather than market feeds. Sentiment Score has the highest proportion of missing values, close to 8.5 percent for both Bitcoin and Ethereum. Search Interest and 7 Day Volatility follow with smaller gaps of about 1.6 and 1.9 percent. Daily Return has roughly 0.5 percent missingness, which corresponds to the initial day of each series when no previous price exists. The core market variables Coin, Date, Price, Volume, and Market Cap are fully observed across the entire year. Bitcoin and Ethereum display almost identical missingness patterns, which indicates that the gaps come from shared upstream sources rather than asset specific issues.\n\n\n\n2.2.2 Missingness Over Time\nUnderstanding how missingness evolves over time provides insight into whether gaps are random or structured. The analysis next focuses on the four variables with missing values to identify the timing and potential causes of these gaps.\n\n\nCode\nvars_with_missing &lt;- c(\n  \"sentiment_score\",\n  \"search_interest\",\n  \"volatility_7d\",\n  \"daily_return\"\n)\n\ndf_long &lt;- df |&gt;\n  select(date, coin, all_of(vars_with_missing)) |&gt;\n  pivot_longer(\n    cols = all_of(vars_with_missing),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |&gt;\n  mutate(\n    missing = is.na(value),\n    variable = recode(variable,\n      sentiment_score = \"Sentiment Score\",\n      search_interest = \"Search Interest\",\n      volatility_7d   = \"7-Day Volatility\",\n      daily_return    = \"Daily Return\"\n    )\n  ) |&gt;\n  filter(missing)\n\nggplot(df_long, aes(x = date, y = variable)) +\n  geom_point(color = \"#e6550d\", size = 3) +\n  facet_wrap(~ coin, ncol = 1) +\n  labs(\n    x = \"Date\",\n    y = \"Variable\",\n    title = \"Missingness Over Time by Variable\"\n  ) +\n  theme_grey(base_size = 16)\n\n\n\n\n\n\n\n\n\nMissingness occurs in well-defined locations rather than at random. Sentiment Score and Search Interest share identical missing dates late in the year for both coins, which points to temporary gaps in the external data sources rather than issues with the market data itself. Daily Return is missing only on the first available date, where it cannot be computed, and 7-Day Volatility is missing during the first six days of each series due to the rolling-window requirement.\n\n\n\n2.2.3 Price Behavior on Missing vs. Non-Missing Days\nSince the gaps for sentiment score and search interest originate from upstream data limitations, the next step is to determine whether imputation is appropriate. Given that the dataset covers only one year for each asset, retaining as many observations as possible is valuable. However, imputation should only be applied if missingness is unrelated to unusual market conditions. For this reason, I examine whether missingness in the externally sourced variables aligns with abnormal price behavior before deciding how to proceed.\n\n\nCode\ndf |&gt;\n  mutate(\n    sent_missing = if_else(is.na(sentiment_score), \"Missing\", \"Present\")\n  ) |&gt;\n  ggplot(aes(x = sent_missing, y = price)) +\n  geom_boxplot(fill = \"#3182bd\", alpha = 0.45, color = \"black\", linewidth = 0.7) +\n  facet_wrap(~ coin, ncol = 2, scales = \"free_y\") +\n  labs(\n    x = \"Sentiment Score Status\",\n    y = \"Price\",\n    title = \"Price Levels on Days With and Without Missing Sentiment\"\n  ) +\n  theme_grey(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt;\n  mutate(\n    search_missing = if_else(is.na(search_interest), \"Missing\", \"Present\")\n  ) |&gt;\n  ggplot(aes(x = search_missing, y = price)) +\n  geom_boxplot(fill = \"#3182bd\", alpha = 0.45, color = \"black\", linewidth = 0.7) +\n  facet_wrap(~ coin, ncol = 2, scales = \"free_y\") +\n  labs(\n    x = \"Search Interest Status\",\n    y = \"Price\",\n    title = \"Price Levels on Days With and Without Missing Search Interest\"\n  ) +\n  theme_grey(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nSentiment Score: Price levels look similar on days with and without missing sentiment, with overlapping medians and interquartile ranges. This suggests that missingness in sentiment does not correspond to unusual market conditions. The gaps likely reflect coverage issues in the sentiment feed rather than price movements.\nSearch Interest: Price distributions again overlap closely, indicating that missing search interest values are not linked to abnormal price behavior. Google Trends often omits low-volume days or returns incomplete windows, and the pattern here aligns with those expected limitations.\n\n\n2.2.4 Imputation Strategy\nLinear interpolation is used only for Sentiment Score and Search Interest, since their missing values come from gaps in the external APIs rather than from anything inherent to the data. In contrast, the early missing values in Daily Return and 7-Day Volatility are expected, because these metrics cannot be computed at the start of the series, so those NA values are left in place. This strikes a balance between preserving the meaning of the derived variables and smoothing the two externally sourced features. Because the dataset is fairly small (one year per coin), filling these external gaps also helps avoid unnecessarily losing observations, even though the overall amount of missingness is low.\n\n\nCode\ndf_imputed &lt;- df |&gt;\n  arrange(coin, date) |&gt;\n  group_by(coin) |&gt;\n  mutate(\n    sentiment_score_imp = na.approx(sentiment_score, na.rm = FALSE),\n    search_interest_imp = na.approx(search_interest, na.rm = FALSE),\n    daily_return_imp    = daily_return,\n    volatility_7d_imp   = volatility_7d\n  ) |&gt;\n  ungroup()\n\ndf_imputed |&gt;\n  summarize(\n    sentiment_original_NA = sum(is.na(sentiment_score)),\n    sentiment_filled_NA   = sum(is.na(sentiment_score_imp)),\n    search_original_NA    = sum(is.na(search_interest)),\n    search_filled_NA      = sum(is.na(search_interest_imp))\n  )\n\n\n\n\n2.2.5 Outlier Detection\nIt is also useful to check for unusually large or extreme observations. Because the variables in this dataset operate on very different scales, some extreme points may not be obvious at first glance. Looking for outliers helps confirm that the data behave as expected during periods of high market activity and ensures that no unexpected spikes are the result of data errors. This step provides an additional check on data quality before moving into the exploratory analysis.\nVariables vary widely in scale, so outlier detection uses standardized Z-scores. This produces a comparable frame of reference and highlights unusually large deviations.\n\n\nCode\ndf_z &lt;- df |&gt;\n  mutate(across(\n    c(price, volume, market_cap,\n      sentiment_score, search_interest,\n      daily_return, volatility_7d),\n    ~ scale(.)[,1],\n    .names = \"{.col}_z\"\n  ))\n\ndf_z |&gt;\n  select(coin, ends_with(\"_z\")) |&gt;\n  pivot_longer(\n    cols = ends_with(\"_z\"),\n    names_to = \"variable\",\n    values_to = \"z\"\n  ) |&gt;\n  mutate(\n    variable = gsub(\"_z\", \"\", variable),\n    variable = recode(variable,\n      price = \"Price\",\n      volume = \"Volume\",\n      market_cap = \"Market Cap\",\n      sentiment_score = \"Sentiment Score\",\n      search_interest = \"Search Interest\",\n      daily_return = \"Daily Return\",\n      volatility_7d = \"7 Day Volatility\"\n    )\n  ) |&gt;\n  ggplot(aes(x = coin, y = z, fill = coin)) +\n  geom_boxplot(outlier.color = \"#e6550d\", alpha = 0.6) +\n  geom_hline(yintercept = 3,  linetype = \"dashed\", color = \"red\") +\n  geom_hline(yintercept = -3, linetype = \"dashed\", color = \"red\") +\n  facet_wrap(~ variable, scales = \"free_y\", ncol = 3) +\n  labs(\n    title = \"Outlier Detection Using Standardized Z-Scores\",\n    x = \"Coin\",\n    y = \"Z-Score\"\n  ) +\n  theme_grey(base_size = 15) + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nStandardizing the variables makes it easier to compare their distributions. A few observations fall beyond ±3 standard deviations for Volume, Daily Return, and Seven Day Volatility. These points line up with periods of sharp price swings or heavy trading, which are typical features of cryptocurrency markets. Sentiment and Search Interest show occasional spikes during times of increased public attention. None of these observations indicate problems with data quality, so all values are kept in the dataset.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  }
]